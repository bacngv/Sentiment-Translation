{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Model - Translator English to Vietnamese - Training"
      ],
      "metadata": {
        "id": "SeAVu-c5Ki37"
      },
      "id": "SeAVu-c5Ki37"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "-_oRQLRPKi38"
      },
      "id": "-_oRQLRPKi38"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install underthesea"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:35:36.603400Z",
          "iopub.execute_input": "2024-06-16T09:35:36.603734Z",
          "iopub.status.idle": "2024-06-16T09:35:51.509208Z",
          "shell.execute_reply.started": "2024-06-16T09:35:36.603705Z",
          "shell.execute_reply": "2024-06-16T09:35:51.508149Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqxmYiB6Ki39",
        "outputId": "824b6281-f533-4235-c2d5-9be5f911a3c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting underthesea\n",
            "  Downloading underthesea-6.8.3-py3-none-any.whl (20.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from underthesea) (8.1.7)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from underthesea) (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from underthesea) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from underthesea) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from underthesea) (6.0.1)\n",
            "Collecting underthesea-core==1.0.4 (from underthesea)\n",
            "  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->underthesea) (2024.5.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2024.6.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (3.5.0)\n",
            "Installing collected packages: underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.10 underthesea-6.8.3 underthesea-core-1.0.4\n"
          ]
        }
      ],
      "id": "kqxmYiB6Ki39"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga9qb27UKzB9",
        "outputId": "9468815c-76c6-46bf-a9f2-31f1dd27ea7e"
      },
      "id": "ga9qb27UKzB9",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re,string # For Regular Expressions, string handle\n",
        "from typing import Iterable, List # For building vocab, yield helper\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Dataset\n",
        "from datasets import load_from_disk\n",
        "\n",
        "# Natural language Processing & Initializing Vocabulary\n",
        "from underthesea import word_tokenize\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "\n",
        "# Building Transformer and Training\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence # take the max size and add padding_token to the smaller\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:35:51.510981Z",
          "iopub.execute_input": "2024-06-16T09:35:51.511336Z",
          "iopub.status.idle": "2024-06-16T09:35:58.049521Z",
          "shell.execute_reply.started": "2024-06-16T09:35:51.511307Z",
          "shell.execute_reply": "2024-06-16T09:35:58.048562Z"
        },
        "trusted": true,
        "id": "s4VIg1KyKi3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51284767-f6a9-4f3e-af14-1e6b2153036b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No module named 'fasttext'\n"
          ]
        }
      ],
      "id": "s4VIg1KyKi3-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "ZnRUyXjXKi3-"
      },
      "id": "ZnRUyXjXKi3-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "dataset = load_from_disk(\"/content/mt-en-vi\")\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sKPsmrJL2td",
        "outputId": "753d3de6-d001-4750-fc68-12cc0abe8f6d"
      },
      "id": "7sKPsmrJL2td",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['en', 'vi', 'source'],\n",
              "        num_rows: 2884451\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['en', 'vi', 'source'],\n",
              "        num_rows: 11316\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['en', 'vi', 'source'],\n",
              "        num_rows: 11225\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Just take 500.000 rows from train, all for others"
      ],
      "metadata": {
        "id": "DbJjthp7Ki3-"
      },
      "id": "DbJjthp7Ki3-"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.DataFrame(dataset['train'][:200000]).drop(columns=['source'])\n",
        "df_valid = pd.DataFrame(dataset['validation']).drop(columns=['source'])\n",
        "df_test = pd.DataFrame(dataset['test']).drop(columns=['source'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:21.386193Z",
          "iopub.execute_input": "2024-06-16T09:36:21.386813Z",
          "iopub.status.idle": "2024-06-16T09:36:23.506317Z",
          "shell.execute_reply.started": "2024-06-16T09:36:21.386784Z",
          "shell.execute_reply": "2024-06-16T09:36:23.505204Z"
        },
        "trusted": true,
        "id": "aHU0sCuTKi3-"
      },
      "execution_count": 6,
      "outputs": [],
      "id": "aHU0sCuTKi3-"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(3), df_valid.head(3), df_test.head(3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:23.507500Z",
          "iopub.execute_input": "2024-06-16T09:36:23.507867Z",
          "iopub.status.idle": "2024-06-16T09:36:23.520427Z",
          "shell.execute_reply.started": "2024-06-16T09:36:23.507832Z",
          "shell.execute_reply": "2024-06-16T09:36:23.519481Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIQLikndKi3_",
        "outputId": "28aa356d-3a10-45e5-ca29-4543e0f318a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                           en  \\\n",
              " 0       - Sorry, that question's not on here.   \n",
              " 1  He wants you to come with him immediately.   \n",
              " 2        I thought we could use some company.   \n",
              " \n",
              "                                                   vi  \n",
              " 0    - Xin lỗi, nhưng mà ở đây không có câu hỏi đấy.  \n",
              " 1          Ông ấy muốn bố đi với ông ấy ngay lập tức  \n",
              " 2  Tôi nghĩ chúng ta có thể muốn vài người bạn đồ...  ,\n",
              "                                                   en  \\\n",
              " 0  In August 1764, Bertin permitted the export of...   \n",
              " 1  Homeless women used to be invisible to me but ...   \n",
              " 2  Pumping water site for artificial infiltration...   \n",
              " \n",
              "                                                   vi  \n",
              " 0  Tháng 8 năm 1764, Bertin lại cho phép xuất khẩ...  \n",
              " 1  Tôi từng không hề để ý đến những người phụ nữ ...  \n",
              " 2        Bơm nước cho thấm nhân tạo ở quận Sojovice.  ,\n",
              "                                                   en  \\\n",
              " 0  And what I think the world needs now is more c...   \n",
              " 1  The group is named after Bangkok, the capital ...   \n",
              " 2  It is surrounded by rivers (Simpson and Coyhai...   \n",
              " \n",
              "                                                   vi  \n",
              " 0  Và tôi nghĩ điều thế giới đang cần bây giờ là ...  \n",
              " 1  Nhóm được đặt theo tên của Bangkok, thủ đô của...  \n",
              " 2  Nó được bao quanh bởi các con sông (Simpson và...  )"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "id": "VIQLikndKi3_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- So:\n",
        "\n",
        "The training data has 500,000 rows.\n",
        "\n",
        "The validation data has 11,316 rows.\n",
        "\n",
        "The test data has 11225 rows."
      ],
      "metadata": {
        "id": "h57FJaX9Ki3_"
      },
      "id": "h57FJaX9Ki3_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "ubpKmJq7Ki3_"
      },
      "id": "ubpKmJq7Ki3_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Check Missing values"
      ],
      "metadata": {
        "id": "VpUMfW5mKi3_"
      },
      "id": "VpUMfW5mKi3_"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Data: \")\n",
        "print(df_train.isna().sum())\n",
        "\n",
        "print(\"Validation Data: \")\n",
        "print(df_valid.isna().sum())\n",
        "\n",
        "print(\"Test Data: \")\n",
        "print(df_test.isna().sum())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:23.521985Z",
          "iopub.execute_input": "2024-06-16T09:36:23.522788Z",
          "iopub.status.idle": "2024-06-16T09:36:23.582071Z",
          "shell.execute_reply.started": "2024-06-16T09:36:23.522754Z",
          "shell.execute_reply": "2024-06-16T09:36:23.581188Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgTyOia9Ki3_",
        "outputId": "2a7d835c-0426-48f0-d055-70798c32d32d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data: \n",
            "en    0\n",
            "vi    0\n",
            "dtype: int64\n",
            "Validation Data: \n",
            "en    0\n",
            "vi    0\n",
            "dtype: int64\n",
            "Test Data: \n",
            "en    0\n",
            "vi    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "id": "QgTyOia9Ki3_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Sentences cleaning: some sentences will have a few mini errors. More than one ' ' or having special symbols for example."
      ],
      "metadata": {
        "id": "YK-KN_BDKi3_"
      },
      "id": "YK-KN_BDKi3_"
    },
    {
      "cell_type": "code",
      "source": [
        "def SentenceCleaning(df):\n",
        "\n",
        "    # Cleaning\n",
        "    df['en'] = df['en'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation))) # Make a new trans without punctuation\n",
        "    df['vi'] = df['vi'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "    df['en'] = df['en'].str.lower() # To easy and smaller vocab we should lower\n",
        "    df['vi'] = df['vi'].str.lower()\n",
        "\n",
        "    df['en'] = df['en'].str.strip() # clear spaces in the beginning and end of sentence\n",
        "    df['vi'] = df['vi'].str.strip()\n",
        "\n",
        "    df['en'] = df['en'].apply(lambda x: re.sub('\\s+',' ',x)) # replace '       ' to ' ' for example\n",
        "    df['vi'] = df['vi'].apply(lambda x: re.sub('\\s+',' ',x))\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:23.583129Z",
          "iopub.execute_input": "2024-06-16T09:36:23.583454Z",
          "iopub.status.idle": "2024-06-16T09:36:23.591270Z",
          "shell.execute_reply.started": "2024-06-16T09:36:23.583427Z",
          "shell.execute_reply": "2024-06-16T09:36:23.590284Z"
        },
        "trusted": true,
        "id": "pIF8cfSxKi3_"
      },
      "execution_count": 9,
      "outputs": [],
      "id": "pIF8cfSxKi3_"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = SentenceCleaning(df_train)\n",
        "df_valid = SentenceCleaning(df_valid)\n",
        "df_test = SentenceCleaning(df_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:23.592657Z",
          "iopub.execute_input": "2024-06-16T09:36:23.593111Z",
          "iopub.status.idle": "2024-06-16T09:36:31.352844Z",
          "shell.execute_reply.started": "2024-06-16T09:36:23.593075Z",
          "shell.execute_reply": "2024-06-16T09:36:31.352026Z"
        },
        "trusted": true,
        "id": "hGG1NXV-Ki3_"
      },
      "execution_count": 10,
      "outputs": [],
      "id": "hGG1NXV-Ki3_"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:31.353981Z",
          "iopub.execute_input": "2024-06-16T09:36:31.354312Z",
          "iopub.status.idle": "2024-06-16T09:36:31.366000Z",
          "shell.execute_reply.started": "2024-06-16T09:36:31.354285Z",
          "shell.execute_reply": "2024-06-16T09:36:31.364986Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "YvaukE5HKi3_",
        "outputId": "cff40f78-84e5-46ef-ad90-a0730609730c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  en  \\\n",
              "0                   sorry that questions not on here   \n",
              "1          he wants you to come with him immediately   \n",
              "2                i thought we could use some company   \n",
              "3  it was founded in 2008 by this anonymous progr...   \n",
              "4  with both of these methods no two prints are e...   \n",
              "5  from these contexts was born an installation i...   \n",
              "6  i have lived to see something which i never ex...   \n",
              "7  it is the model for all future relationships w...   \n",
              "8                        welcome him as your brother   \n",
              "9  so biologists can make all the mutant fruit fl...   \n",
              "\n",
              "                                                  vi  \n",
              "0        xin lỗi nhưng mà ở đây không có câu hỏi đấy  \n",
              "1          ông ấy muốn bố đi với ông ấy ngay lập tức  \n",
              "2  tôi nghĩ chúng ta có thể muốn vài người bạn đồ...  \n",
              "3  nó được sáng lập vào năm 2008 bởi một lập trìn...  \n",
              "4  với cả hai phương pháp không có hai bản in nào...  \n",
              "5  từ những tình huống này một bố trí không gian ...  \n",
              "6  ta đã sống để thấy điều ta không bao giờ mong đợi  \n",
              "7  đó là mô hình cho tất cả các mối quan hệ trong...  \n",
              "8                chào mừng nó như anh em của các con  \n",
              "9  vậy các nhà sinh vật học có thể biến đổi gene ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-950d9481-5a67-477a-b55a-609d893096ae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>vi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sorry that questions not on here</td>\n",
              "      <td>xin lỗi nhưng mà ở đây không có câu hỏi đấy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>he wants you to come with him immediately</td>\n",
              "      <td>ông ấy muốn bố đi với ông ấy ngay lập tức</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i thought we could use some company</td>\n",
              "      <td>tôi nghĩ chúng ta có thể muốn vài người bạn đồ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>it was founded in 2008 by this anonymous progr...</td>\n",
              "      <td>nó được sáng lập vào năm 2008 bởi một lập trìn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>with both of these methods no two prints are e...</td>\n",
              "      <td>với cả hai phương pháp không có hai bản in nào...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>from these contexts was born an installation i...</td>\n",
              "      <td>từ những tình huống này một bố trí không gian ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>i have lived to see something which i never ex...</td>\n",
              "      <td>ta đã sống để thấy điều ta không bao giờ mong đợi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>it is the model for all future relationships w...</td>\n",
              "      <td>đó là mô hình cho tất cả các mối quan hệ trong...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>welcome him as your brother</td>\n",
              "      <td>chào mừng nó như anh em của các con</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>so biologists can make all the mutant fruit fl...</td>\n",
              "      <td>vậy các nhà sinh vật học có thể biến đổi gene ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-950d9481-5a67-477a-b55a-609d893096ae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-950d9481-5a67-477a-b55a-609d893096ae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-950d9481-5a67-477a-b55a-609d893096ae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-467e2257-6786-4892-adc8-0c668bbe79ad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-467e2257-6786-4892-adc8-0c668bbe79ad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-467e2257-6786-4892-adc8-0c668bbe79ad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "id": "YvaukE5HKi3_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Check for rows that contain words that are not within the range of the source and target languages\n",
        "\n",
        "Both English and Vietnamese use the Latin alphabet, but Vietnamese adds diacritics to create special characters to represent different sounds. To filter out lines with words that do not belong to English and Vietnamese, we use appropriate regular expressions"
      ],
      "metadata": {
        "id": "Y6l3u0xoKi3_"
      },
      "id": "Y6l3u0xoKi3_"
    },
    {
      "cell_type": "code",
      "source": [
        "def language_filter(df):\n",
        "    def is_valid_language_sentence(sentence):\n",
        "        pattern = re.compile(r'^[A-Za-zÀ-ỹà-ỹ\\s]*$')\n",
        "        return bool(pattern.match(sentence))\n",
        "    filtered_df = df[df['en'].apply(is_valid_language_sentence) & df['vi'].apply(is_valid_language_sentence)]\n",
        "    return filtered_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:31.409558Z",
          "iopub.execute_input": "2024-06-16T09:36:31.410180Z",
          "iopub.status.idle": "2024-06-16T09:36:31.415047Z",
          "shell.execute_reply.started": "2024-06-16T09:36:31.410148Z",
          "shell.execute_reply": "2024-06-16T09:36:31.414149Z"
        },
        "trusted": true,
        "id": "bA_CQcyTKi4A"
      },
      "execution_count": 12,
      "outputs": [],
      "id": "bA_CQcyTKi4A"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_filter = language_filter(df_train)\n",
        "df_valid_filter = language_filter(df_valid)\n",
        "df_test_filter = language_filter(df_test)\n",
        "\n",
        "print(f'Train: before: {df_train.shape[0]} - after: {df_train_filter.shape[0]}')\n",
        "print(f'valid: before: {df_valid.shape[0]} - after: {df_valid_filter.shape[0]}')\n",
        "print(f'test: before: {df_test.shape[0]} - after: {df_test_filter.shape[0]}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:31.416251Z",
          "iopub.execute_input": "2024-06-16T09:36:31.416585Z",
          "iopub.status.idle": "2024-06-16T09:36:32.513444Z",
          "shell.execute_reply.started": "2024-06-16T09:36:31.416562Z",
          "shell.execute_reply": "2024-06-16T09:36:32.512491Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tkb71zBKi4A",
        "outputId": "55d1f700-796b-4611-c3a3-b9e376b5ef78"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: before: 200000 - after: 156398\n",
            "valid: before: 11316 - after: 8596\n",
            "test: before: 11225 - after: 8560\n"
          ]
        }
      ],
      "id": "6Tkb71zBKi4A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see, lots of rows have some words which are unrelated to its language! (20% - 30% data)\n",
        "\n",
        "If we use the raw dataframe to create the vocabulary, the size will be very large leading to 'Issue 03: CUDA out of memory'.\n",
        "\n",
        "How about using df_filter? Smaller size vocabulary will be created. But we will ignore correct words in invalid lines containing incorrect words and make the model ineffective.\n",
        "\n",
        "**My solution:** With the invalid rows, just remove the wrong words and use another words and valid words in valid rows to initialize a vocabulary. This will keep important word and minimize the unrelated words in vocabulary. (Reuslt: the size of the vocabulary has been halved)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-15T20:18:48.106916Z",
          "iopub.execute_input": "2024-06-15T20:18:48.107611Z",
          "iopub.status.idle": "2024-06-15T20:18:48.115417Z",
          "shell.execute_reply.started": "2024-06-15T20:18:48.107577Z",
          "shell.execute_reply": "2024-06-15T20:18:48.114210Z"
        },
        "id": "r5mj1jfEKi4A"
      },
      "id": "r5mj1jfEKi4A"
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_tomake_vocab(sentence):\n",
        "    sentence = re.sub(r'^[A-Za-zÀ-ỹà-ỹ\\s]*$', '', sentence)\n",
        "    return sentence\n",
        "\n",
        "df_tomake_vocab = pd.concat([df_train, df_valid], ignore_index=True)\n",
        "df_tomake_vocab['en'] = df_tomake_vocab['en'].apply(sentence_tomake_vocab)\n",
        "df_tomake_vocab['vi'] = df_tomake_vocab['vi'].apply(sentence_tomake_vocab)\n",
        "df_tomake_vocab = SentenceCleaning(df_tomake_vocab)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:32.514501Z",
          "iopub.execute_input": "2024-06-16T09:36:32.514779Z",
          "iopub.status.idle": "2024-06-16T09:36:37.134121Z",
          "shell.execute_reply.started": "2024-06-16T09:36:32.514754Z",
          "shell.execute_reply": "2024-06-16T09:36:37.133059Z"
        },
        "trusted": true,
        "id": "2DAym3RmKi4A"
      },
      "execution_count": 14,
      "outputs": [],
      "id": "2DAym3RmKi4A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Building **Tokenizer** and **Vocabulary**\n",
        "\n",
        "With English - The most popular international language, **'torchtext.data.utils.get_tokenizer'** support the default language with 'en' - English. But Vietnamese has not already been supported.\n",
        "\n",
        "But get_tokenizer allow us to transmission the function word_token returning a list to get_tokenizer. Then, the problems lead to what framework supports to Vietnamese. It must be Underthesea - the best support to Vietnamese in NLP\n",
        "\n",
        "You can read **[torchtext - doc](https://pytorch.org/text/stable/data_utils.html)**!"
      ],
      "metadata": {
        "id": "PyaJ_OddKi4A"
      },
      "id": "PyaJ_OddKi4A"
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_LANGUAGE = 'en'\n",
        "TGT_LANGUAGE = 'vi'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:37.135820Z",
          "iopub.execute_input": "2024-06-16T09:36:37.136258Z",
          "iopub.status.idle": "2024-06-16T09:36:37.142075Z",
          "shell.execute_reply.started": "2024-06-16T09:36:37.136205Z",
          "shell.execute_reply": "2024-06-16T09:36:37.139878Z"
        },
        "trusted": true,
        "id": "Sv3iFl6RKi4A"
      },
      "execution_count": 15,
      "outputs": [],
      "id": "Sv3iFl6RKi4A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Tokenizer**"
      ],
      "metadata": {
        "id": "A60OuovcKi4A"
      },
      "id": "A60OuovcKi4A"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = {}\n",
        "\n",
        "# Tokenizer for English\n",
        "tokenizer[SRC_LANGUAGE] = get_tokenizer('basic_english')\n",
        "\n",
        "# Tokenizer for Vietnamese\n",
        "# Need help with Underthesea\n",
        "def vi_tokenize(sentence):\n",
        "    return word_tokenize(sentence) # word_tokenize from undersea supporting vietnamese\n",
        "tokenizer[TGT_LANGUAGE] = get_tokenizer(vi_tokenize)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:37.143194Z",
          "iopub.execute_input": "2024-06-16T09:36:37.143508Z",
          "iopub.status.idle": "2024-06-16T09:36:37.503908Z",
          "shell.execute_reply.started": "2024-06-16T09:36:37.143484Z",
          "shell.execute_reply": "2024-06-16T09:36:37.502801Z"
        },
        "trusted": true,
        "id": "SaN9pIVpKi4A"
      },
      "execution_count": 16,
      "outputs": [],
      "id": "SaN9pIVpKi4A"
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer[SRC_LANGUAGE](\"hello can you help me\"))\n",
        "print(tokenizer[TGT_LANGUAGE](\"xin chào bạn có thể giúp tôi không\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:37.505311Z",
          "iopub.execute_input": "2024-06-16T09:36:37.505686Z",
          "iopub.status.idle": "2024-06-16T09:36:37.978621Z",
          "shell.execute_reply.started": "2024-06-16T09:36:37.505651Z",
          "shell.execute_reply": "2024-06-16T09:36:37.977276Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7cjFD2ZKi4B",
        "outputId": "df486793-5aeb-46aa-fd2d-5bff8005f9ae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'can', 'you', 'help', 'me']\n",
            "['xin', 'chào bạn', 'có thể', 'giúp', 'tôi', 'không']\n"
          ]
        }
      ],
      "id": "s7cjFD2ZKi4B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that this Tokenizer will generate dictionaries with words and not characters as we tested before and failed."
      ],
      "metadata": {
        "id": "ctq4MAsMKi4B"
      },
      "id": "ctq4MAsMKi4B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Vocabulary**\n",
        "\n",
        "Build a Vocab from an iterator.\n",
        "```python\n",
        "torchtext.vocab.build_vocab_from_iterator(iterator: Iterable, min_freq: int = 1, specials: Optional[List[str]] = None, special_first: bool = True, max_tokens: Optional[int] = None) → Vocab\n",
        "```\n",
        "\n",
        "> - Parameters:\n",
        "\n",
        "**iterator** – Iterator used to build Vocab. Must **yield** list or iterator of tokens.\n",
        "\n",
        "**min_freq** – The minimum frequency needed to include a token in the vocabulary.\n",
        "\n",
        "**specials** – Special symbols to add. The order of supplied tokens will be preserved.\n",
        "\n",
        "**special_first** – Indicates whether to insert symbols at the beginning or at the end.\n",
        "\n",
        "**max_tokens** – If provided, creates the vocab from the max_tokens - len(specials) most frequent tokens.\n",
        "\n"
      ],
      "metadata": {
        "id": "5gX4-vzgKi4B"
      },
      "id": "5gX4-vzgKi4B"
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_token_helper(iterator : Iterable, language: str) -> List[str]:\n",
        "    for num_iter, sample_iter in iterator:\n",
        "        yield tokenizer[language](sample_iter[language])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:37.980433Z",
          "iopub.execute_input": "2024-06-16T09:36:37.980852Z",
          "iopub.status.idle": "2024-06-16T09:36:37.986843Z",
          "shell.execute_reply.started": "2024-06-16T09:36:37.980809Z",
          "shell.execute_reply": "2024-06-16T09:36:37.985379Z"
        },
        "trusted": true,
        "id": "JM4FxsIOKi4B"
      },
      "execution_count": 18,
      "outputs": [],
      "id": "JM4FxsIOKi4B"
    },
    {
      "cell_type": "code",
      "source": [
        "# Special Symbols\n",
        "UNKNOWN_TOKEN, PADDING_TOKEN, START_TOKEN, END_TOKEN = '<unk>', '<pad>', '<bos>', '<eos>'\n",
        "UNKNOWN_IDX, PADDING_IDX, START_IDX, END_IDX = 0,1,2,3"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:37.988738Z",
          "iopub.execute_input": "2024-06-16T09:36:37.989193Z",
          "iopub.status.idle": "2024-06-16T09:36:38.732196Z",
          "shell.execute_reply.started": "2024-06-16T09:36:37.989140Z",
          "shell.execute_reply": "2024-06-16T09:36:38.731090Z"
        },
        "trusted": true,
        "id": "qoSIsWg9Ki4B"
      },
      "execution_count": 19,
      "outputs": [],
      "id": "qoSIsWg9Ki4B"
    },
    {
      "cell_type": "code",
      "source": [
        "# Building vocab\n",
        "def vocab_building(df):\n",
        "    vocab = {}\n",
        "    for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "        iterator = df.iterrows()\n",
        "        vocab[language] = build_vocab_from_iterator(\n",
        "            iterator=yield_token_helper(iterator, language),\n",
        "            min_freq=1,\n",
        "            specials=[UNKNOWN_TOKEN, PADDING_TOKEN, START_TOKEN, END_TOKEN], # List special symbols\n",
        "            special_first=True\n",
        "        )\n",
        "\n",
        "    for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "        vocab[language].set_default_index(UNKNOWN_IDX)\n",
        "    return vocab"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:38.735826Z",
          "iopub.execute_input": "2024-06-16T09:36:38.736277Z",
          "iopub.status.idle": "2024-06-16T09:36:38.816999Z",
          "shell.execute_reply.started": "2024-06-16T09:36:38.736219Z",
          "shell.execute_reply": "2024-06-16T09:36:38.815791Z"
        },
        "trusted": true,
        "id": "WHbu4hGTKi4B"
      },
      "execution_count": 20,
      "outputs": [],
      "id": "WHbu4hGTKi4B"
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = vocab_building(df_tomake_vocab)\n",
        "vocabulary"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:36:38.818484Z",
          "iopub.execute_input": "2024-06-16T09:36:38.818818Z",
          "iopub.status.idle": "2024-06-16T09:38:21.466241Z",
          "shell.execute_reply.started": "2024-06-16T09:36:38.818793Z",
          "shell.execute_reply": "2024-06-16T09:38:21.465356Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oE74ppzKi4B",
        "outputId": "52a42d4e-9d56-41fd-aee9-69b540d0b87a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': Vocab(), 'vi': Vocab()}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "id": "6oE74ppzKi4B"
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary[SRC_LANGUAGE]['who']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:38:21.467331Z",
          "iopub.execute_input": "2024-06-16T09:38:21.467595Z",
          "iopub.status.idle": "2024-06-16T09:38:21.473097Z",
          "shell.execute_reply.started": "2024-06-16T09:38:21.467573Z",
          "shell.execute_reply": "2024-06-16T09:38:21.472253Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9gH0QE4Ki4B",
        "outputId": "3395e17a-ae03-439d-d586-4bb3a9bd8a50"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "id": "W9gH0QE4Ki4B"
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary[TGT_LANGUAGE]['nào']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:38:21.474191Z",
          "iopub.execute_input": "2024-06-16T09:38:21.474484Z",
          "iopub.status.idle": "2024-06-16T09:38:21.485056Z",
          "shell.execute_reply.started": "2024-06-16T09:38:21.474461Z",
          "shell.execute_reply": "2024-06-16T09:38:21.484253Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO2ygEvxKi4B",
        "outputId": "472bebd6-cd52-4c86-eb39-faa1d9dacc00"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "222"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "id": "wO2ygEvxKi4B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Complete Model\n",
        "\n",
        "- Use some of the classes, functions available in torch.nn. If you want a program from scratch, please check ModelBuilding.ipynb\n",
        "- Input/Output shape: (seq, batch, feature). We can change this by this parameter:\n",
        "\n",
        "```python\n",
        "batch_first (bool)\n",
        "```\n",
        "\n",
        "\n",
        "– If True, then the input and output tensors are provided as (batch, seq, feature). Default: False (seq, batch, feature)."
      ],
      "metadata": {
        "id": "bhqEeuG5Ki4C"
      },
      "id": "bhqEeuG5Ki4C"
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size:int, d_model:int):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding_layer = nn.Embedding(vocab_size, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, tokens: torch.Tensor):\n",
        "        return self.embedding_layer(tokens.long()) * math.sqrt(self.d_model)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, max_length_seq:int, d_model:int, dropout_rate:float):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, d_model, 2)* math.log(10000) / d_model)\n",
        "        pos = torch.arange(0, max_length_seq).reshape(max_length_seq, 1)\n",
        "        PE = torch.zeros((max_length_seq, d_model))\n",
        "        PE[:, 0::2] = torch.sin(pos * den)\n",
        "        PE[:, 1::2] = torch.cos(pos * den)\n",
        "        PE = PE.unsqueeze(-2)\n",
        "        self.register_buffer(\"PE\", PE)\n",
        "        self.dropout_layer = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, token_embedding: torch.Tensor):\n",
        "        return self.dropout_layer(token_embedding + self.PE[:token_embedding.size(0), :])\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 src_vocab_size:int,\n",
        "                 tgt_vocab_size:int,\n",
        "                 d_model:int,\n",
        "                 nhead:int,\n",
        "                 num_encoder_layers:int,\n",
        "                 num_decoder_layers:int,\n",
        "                 dim_feedforward:int,\n",
        "                 dropout:float,\n",
        "                 max_length_seq=20000):\n",
        "        super(TransformerModel,self).__init__()\n",
        "        # Input Preprocessing\n",
        "        self.input_token_embedding = TokenEmbedding(vocab_size=src_vocab_size,d_model=d_model)\n",
        "\n",
        "        # Output Preprocessing\n",
        "        self.output_token_embedding = TokenEmbedding(vocab_size=tgt_vocab_size,d_model=d_model)\n",
        "\n",
        "        # Positional Encoding\n",
        "        self.positional_encoding = PositionalEncoding(max_length_seq=max_length_seq,d_model=d_model,dropout_rate=dropout)\n",
        "\n",
        "        # Transformer Architecture with Encoder & Decoder (available nn.Transformer)\n",
        "        self.transformer = nn.Transformer(d_model=d_model,\n",
        "                                          nhead=nhead,\n",
        "                                          num_encoder_layers=num_encoder_layers,\n",
        "                                          num_decoder_layers=num_decoder_layers,\n",
        "                                          dim_feedforward=dim_feedforward,\n",
        "                                          dropout=dropout)\n",
        "\n",
        "        # Linear Layer\n",
        "        self.generator = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "    def forward(self,\n",
        "                src: torch.Tensor,\n",
        "                tgt: torch.Tensor,\n",
        "                src_mask: torch.Tensor,\n",
        "                tgt_mask: torch.Tensor,\n",
        "                src_key_padding_mask: torch.Tensor,\n",
        "                tgt_key_padding_mask: torch.Tensor,\n",
        "                memory_key_padding_mask: torch.Tensor):\n",
        "\n",
        "        # Pre-processing\n",
        "        src_embedding = self.positional_encoding(self.input_token_embedding(src))\n",
        "        tgt_embedding = self.positional_encoding(self.output_token_embedding(tgt))\n",
        "\n",
        "        output = self.transformer(src_embedding, tgt_embedding, src_mask, tgt_mask, None, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(output)\n",
        "\n",
        "\n",
        "    def encode(self, src: torch.Tensor, src_mask: torch.Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.input_token_embedding(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: torch.Tensor, memory: torch.Tensor, tgt_mask: torch.Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.output_token_embedding(tgt)), memory,\n",
        "                          tgt_mask)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:38:21.486297Z",
          "iopub.execute_input": "2024-06-16T09:38:21.486549Z",
          "iopub.status.idle": "2024-06-16T09:38:21.504054Z",
          "shell.execute_reply.started": "2024-06-16T09:38:21.486528Z",
          "shell.execute_reply": "2024-06-16T09:38:21.503383Z"
        },
        "trusted": true,
        "id": "ae-WUMzSKi4C"
      },
      "execution_count": 24,
      "outputs": [],
      "id": "ae-WUMzSKi4C"
    },
    {
      "cell_type": "code",
      "source": [
        "class SupportTransformer:\n",
        "\n",
        "    def __init__(self,\n",
        "                 device,\n",
        "                 src_language:str,\n",
        "                 tgt_language:str,\n",
        "                 start_idx:int,\n",
        "                 end_idx:int,\n",
        "                 pad_idx:int,\n",
        "                 unk_idx:int,\n",
        "                 tokenizer,\n",
        "                 vocabulary):\n",
        "        self.device = device\n",
        "        self.src_language = src_language\n",
        "        self.tgt_language = tgt_language\n",
        "        self.start_idx = start_idx\n",
        "        self.end_idx = end_idx\n",
        "        self.pad_idx = pad_idx\n",
        "        self.unk_idx = unk_idx\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocabulary = vocabulary\n",
        "\n",
        "    def generate_square_subsequent_mask(self, size):\n",
        "        mask = (torch.triu(torch.ones((size, size), device=self.device)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def create_mask(self, src, tgt):\n",
        "        src_seq_len = src.shape[0]\n",
        "        tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "        tgt_mask = self.generate_square_subsequent_mask(tgt_seq_len)\n",
        "        src_mask = torch.zeros((src_seq_len, src_seq_len),device=self.device).type(torch.bool)\n",
        "\n",
        "        src_padding_mask = (src == self.pad_idx).transpose(0, 1)\n",
        "        tgt_padding_mask = (tgt == self.pad_idx).transpose(0, 1)\n",
        "        return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
        "\n",
        "    def preprocessing_sentece(self, sentence:str, options=True): # True for src, False for tgt\n",
        "        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "        sentence = sentence.lower()\n",
        "        sentence = sentence.strip()\n",
        "        sentence = re.sub('\\s+', ' ', sentence)\n",
        "\n",
        "\n",
        "        lang = self.src_language if options else self.tgt_language\n",
        "        # Tokenizer\n",
        "        tokens = self.tokenizer[lang](sentence.rstrip(\"\\n\"))\n",
        "        # vocabulary: text -> number\n",
        "        tokens_idx = self.vocabulary[lang](tokens)\n",
        "        # Add start_token, end_token and append\n",
        "        return torch.cat((torch.tensor([self.start_idx]),\n",
        "                                      torch.tensor(tokens_idx),\n",
        "                                      torch.tensor([self.end_idx])))\n",
        "\n",
        "\n",
        "    def get_batch(self, df):\n",
        "        return list(zip(df[self.src_language], df[self.tgt_language]))\n",
        "\n",
        "    def preprocessing_batch(self,batch):\n",
        "        src_out, tgt_out = [], []\n",
        "\n",
        "        for src_data, tgt_data in batch:\n",
        "            src_out.append(self.preprocessing_sentece(src_data,options=True))\n",
        "            tgt_out.append(self.preprocessing_sentece(tgt_data,options=False))\n",
        "\n",
        "        src_batch, tgt_batch = pad_sequence(src_out, padding_value=self.pad_idx), pad_sequence(tgt_out, padding_value=self.pad_idx)\n",
        "\n",
        "        return src_batch, tgt_batch\n",
        "\n",
        "    def evaluate(self, model, loss_func, df_valid, batch_size=30, accumulation_steps=5):\n",
        "        model.eval()\n",
        "        valid_loss = 0\n",
        "        valid_batch = self.get_batch(df_valid)\n",
        "        valid_dataloader = DataLoader(valid_batch, batch_size=batch_size, collate_fn=self.preprocessing_batch)\n",
        "        for index, (src, tgt) in enumerate(valid_dataloader):\n",
        "            src = src.to(self.device)\n",
        "            tgt = tgt.to(self.device)\n",
        "\n",
        "            tgt_input = tgt[:-1, :] # Without the last word\n",
        "\n",
        "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = self.create_mask(src, tgt_input)\n",
        "\n",
        "            # predictions\n",
        "            predictions = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "            tgt_out = tgt[1:, :]\n",
        "            # Loss\n",
        "            loss = loss_func(predictions.reshape(-1, predictions.shape[-1]), tgt_out.reshape(-1))\n",
        "            loss = loss / accumulation_steps\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "        return valid_loss / len(valid_dataloader)\n",
        "\n",
        "\n",
        "\n",
        "    def train(self, model, optimizer, loss_func, df_train, batch_size = 30, accumulation_steps = 5):\n",
        "        model.train()\n",
        "\n",
        "        train_loss = 0\n",
        "        train_batch = self.get_batch(df_train)\n",
        "        train_dataloader = DataLoader(train_batch, batch_size=batch_size, collate_fn=self.preprocessing_batch)\n",
        "\n",
        "        # Reset grad\n",
        "        optimizer.zero_grad()\n",
        "        for index, (src, tgt) in enumerate(train_dataloader):\n",
        "            src = src.to(self.device)\n",
        "            tgt = tgt.to(self.device)\n",
        "\n",
        "            tgt_input = tgt[:-1, :] # Without the last word\n",
        "\n",
        "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = self.create_mask(src, tgt_input)\n",
        "\n",
        "            # predictions\n",
        "            predictions = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "            tgt_out = tgt[1:, :]\n",
        "            # Loss\n",
        "            loss = loss_func(predictions.reshape(-1, predictions.shape[-1]), tgt_out.reshape(-1))\n",
        "            loss = loss / accumulation_steps\n",
        "            loss.backward()\n",
        "\n",
        "            if (index+1) % accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad() # Reset gradients tensor\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        return train_loss / len(train_dataloader)\n",
        "\n",
        "    def generate(self, model, src_sentence):\n",
        "        start_symbol = self.start_idx\n",
        "        src = self.preprocessing_sentece(src_sentence, True).view(-1, 1)\n",
        "        max_len = src.shape[0]\n",
        "        src_mask = (torch.zeros(max_len, max_len)).type(torch.bool)\n",
        "\n",
        "        src = src.to(self.device)\n",
        "        src_mask = src_mask.to(self.device)\n",
        "\n",
        "        memory = model.encode(src, src_mask)\n",
        "        ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(self.device)\n",
        "        for i in range(max_len-1):\n",
        "            memory = memory.to(self.device)\n",
        "            tgt_mask = (self.generate_square_subsequent_mask(ys.size(0))\n",
        "                        .type(torch.bool)).to(self.device)\n",
        "            out = model.decode(ys, memory, tgt_mask)\n",
        "            out = out.transpose(0, 1)\n",
        "            prob = model.generator(out[:, -1])\n",
        "            _, next_word = torch.max(prob, dim=1) # Greedy\n",
        "            next_word = next_word.item()\n",
        "\n",
        "            ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "            if next_word == self.end_idx:\n",
        "                break\n",
        "\n",
        "        return \" \".join(\n",
        "            self.vocabulary[self.tgt_language].lookup_tokens(list(ys.cpu().numpy()))\n",
        "        ).replace(\n",
        "            self.vocabulary[self.tgt_language].lookup_token(self.start_idx), \"\"\n",
        "        ).replace(\n",
        "            self.vocabulary[self.tgt_language].lookup_token(self.end_idx), \"\"\n",
        "        ).strip()\n",
        "\n",
        "    def completely_generate(self, model, src_sentence):\n",
        "        start_symbol = self.start_idx\n",
        "        src = self.preprocessing_sentece(src_sentence, True)\n",
        "\n",
        "        src = src.view(-1, 1)\n",
        "        max_len = src.shape[0]\n",
        "        src_mask = (torch.zeros(max_len, max_len)).type(torch.bool)\n",
        "\n",
        "        src = src.to(self.device)\n",
        "        src_mask = src_mask.to(self.device)\n",
        "\n",
        "        memory = model.encode(src, src_mask)\n",
        "        ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(self.device)\n",
        "        for i in range(max_len-1):\n",
        "            memory = memory.to(self.device)\n",
        "            tgt_mask = (self.generate_square_subsequent_mask(ys.size(0))\n",
        "                        .type(torch.bool)).to(self.device)\n",
        "            out = model.decode(ys, memory, tgt_mask)\n",
        "            out = out.transpose(0, 1)\n",
        "            prob = model.generator(out[:, -1])\n",
        "            _, next_word = torch.max(prob, dim=1) # Greedy\n",
        "            next_word = next_word.item()\n",
        "\n",
        "            ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "            if next_word == self.end_idx:\n",
        "                break\n",
        "\n",
        "        # Find unkown words in tgt generate\n",
        "        tgt_unk_indexes = torch.nonzero(ys == self.unk_idx).squeeze().tolist()\n",
        "\n",
        "        output_list = self.vocabulary[self.tgt_language].lookup_tokens(list(ys.cpu().numpy()))\n",
        "        src_tokens = self.tokenizer[self.src_language](src_sentence)\n",
        "        for index in tgt_unk_indexes:\n",
        "            if index[0]-1 < len(src_tokens):\n",
        "                output_list[index[0]] = src_tokens[index[0]-1]\n",
        "\n",
        "\n",
        "        return \" \".join(\n",
        "            output_list\n",
        "        ).replace(\n",
        "            self.vocabulary[self.tgt_language].lookup_token(self.start_idx), \"\"\n",
        "        ).replace(\n",
        "            self.vocabulary[self.tgt_language].lookup_token(self.end_idx), \"\"\n",
        "        ).strip()\n",
        "\n",
        "    def training(self, model, optimizer, loss_func, earlystopping, df_train, df_valid, epochs=5, batch_size = 30, accumulation_steps = 5, custom_test=None):\n",
        "        history = {'train_loss': [], 'valid_loss': []}\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            print(f\"Epoch {epoch}: \" + (\"-\" * 80))\n",
        "            start = time.time()\n",
        "            train_loss = self.train(model, optimizer, loss_func, df_train, batch_size, accumulation_steps)\n",
        "            history['train_loss'].append(train_loss)\n",
        "            valid_loss = self.evaluate(model, loss_func, df_valid, batch_size)\n",
        "            history['valid_loss'].append(valid_loss)\n",
        "            print(f\"- Train loss: {train_loss:.3f} - Valid loss: {valid_loss:.3f} - Time training: {(time.time() - start):.3f}\")\n",
        "\n",
        "            # custom_test\n",
        "            if custom_test != None:\n",
        "                print(f\"Input '{self.src_language}': {custom_test}\")\n",
        "                print(f\"Output '{self.tgt_language}' generate: {self.generate(model, custom_test)}\",end=\"\\n\\n\")\n",
        "            else:\n",
        "                print(\"\\n\\n\")\n",
        "\n",
        "            # EarylyStopping\n",
        "            earlystopping(train_loss, valid_loss)\n",
        "            if earlystopping.early_stop:\n",
        "                print(\"Early Stopping active!\")\n",
        "                break\n",
        "        return history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T10:59:14.369732Z",
          "iopub.execute_input": "2024-06-16T10:59:14.370209Z",
          "iopub.status.idle": "2024-06-16T10:59:14.415225Z",
          "shell.execute_reply.started": "2024-06-16T10:59:14.370178Z",
          "shell.execute_reply": "2024-06-16T10:59:14.414276Z"
        },
        "trusted": true,
        "id": "MXMytACaKi4C"
      },
      "execution_count": 25,
      "outputs": [],
      "id": "MXMytACaKi4C"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Model"
      ],
      "metadata": {
        "id": "ntt1-SksKi4G"
      },
      "id": "ntt1-SksKi4G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Config**"
      ],
      "metadata": {
        "id": "aRLHjBwqKi4G"
      },
      "id": "aRLHjBwqKi4G"
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "src_vocab_size = len(vocabulary[SRC_LANGUAGE])\n",
        "tgt_vocab_size = len(vocabulary[TGT_LANGUAGE])\n",
        "d_model = 512\n",
        "nhead = 8 # d_model must be divisible by nhead\n",
        "num_encoder_layers = 2\n",
        "num_decoder_layers = 2\n",
        "dim_feedforward = 512\n",
        "dropout = 0.1\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 30"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:38:21.552015Z",
          "iopub.execute_input": "2024-06-16T09:38:21.552306Z",
          "iopub.status.idle": "2024-06-16T09:38:21.585756Z",
          "shell.execute_reply.started": "2024-06-16T09:38:21.552275Z",
          "shell.execute_reply": "2024-06-16T09:38:21.585056Z"
        },
        "trusted": true,
        "id": "4itYtNDAKi4G"
      },
      "execution_count": 26,
      "outputs": [],
      "id": "4itYtNDAKi4G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Model, Optimizer, EarlyStopping and Loss**"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-14T18:52:20.891679Z",
          "iopub.execute_input": "2024-06-14T18:52:20.892297Z",
          "iopub.status.idle": "2024-06-14T18:52:20.898207Z",
          "shell.execute_reply.started": "2024-06-14T18:52:20.892265Z",
          "shell.execute_reply": "2024-06-14T18:52:20.897134Z"
        },
        "id": "Fa18dhJyKi4G"
      },
      "id": "Fa18dhJyKi4G"
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerModel(src_vocab_size=src_vocab_size,\n",
        "                         tgt_vocab_size=tgt_vocab_size,\n",
        "                         d_model=d_model,\n",
        "                         nhead=nhead,\n",
        "                         num_encoder_layers=num_encoder_layers,\n",
        "                         num_decoder_layers=num_decoder_layers,\n",
        "                         dim_feedforward=dim_feedforward,\n",
        "                         dropout=dropout)\n",
        "model = model.to(device)\n",
        "model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:38:21.586833Z",
          "iopub.execute_input": "2024-06-16T09:38:21.587598Z",
          "iopub.status.idle": "2024-06-16T09:38:23.244519Z",
          "shell.execute_reply.started": "2024-06-16T09:38:21.587573Z",
          "shell.execute_reply": "2024-06-16T09:38:23.243622Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyBaD-TIKi4G",
        "outputId": "db494983-88ba-412f-baee-e20304960281"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerModel(\n",
              "  (input_token_embedding): TokenEmbedding(\n",
              "    (embedding_layer): Embedding(72982, 512)\n",
              "  )\n",
              "  (output_token_embedding): TokenEmbedding(\n",
              "    (embedding_layer): Embedding(71795, 512)\n",
              "  )\n",
              "  (positional_encoding): PositionalEncoding(\n",
              "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-1): 2 x TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-1): 2 x TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (generator): Linear(in_features=512, out_features=71795, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "id": "TyBaD-TIKi4G"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the weights of paramaters which have more than a dimension\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "# Loss\n",
        "loss_func = nn.CrossEntropyLoss(ignore_index=PADDING_IDX)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# EarlyStopping\n",
        "class EarlyStopping():\n",
        "    def __init__(self, tolerance=5, min_delta=0):\n",
        "\n",
        "        self.tolerance = tolerance\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, train_loss, validation_loss):\n",
        "        if (validation_loss - train_loss) > self.min_delta:\n",
        "            self.counter +=1\n",
        "            if self.counter >= self.tolerance:\n",
        "                self.early_stop = True\n",
        "\n",
        "earlystopping  = EarlyStopping(tolerance=5, min_delta=0.1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:38:23.245573Z",
          "iopub.execute_input": "2024-06-16T09:38:23.245844Z",
          "iopub.status.idle": "2024-06-16T09:38:24.021492Z",
          "shell.execute_reply.started": "2024-06-16T09:38:23.245822Z",
          "shell.execute_reply": "2024-06-16T09:38:24.020553Z"
        },
        "trusted": true,
        "id": "3l16Z4sGKi4H"
      },
      "execution_count": 28,
      "outputs": [],
      "id": "3l16Z4sGKi4H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model"
      ],
      "metadata": {
        "id": "nwLofhswKi4H"
      },
      "id": "nwLofhswKi4H"
    },
    {
      "cell_type": "code",
      "source": [
        "sp = SupportTransformer(device=device,\n",
        "                        src_language=SRC_LANGUAGE,\n",
        "                        tgt_language=TGT_LANGUAGE,\n",
        "                        start_idx=START_IDX,\n",
        "                        end_idx=END_IDX,\n",
        "                        pad_idx=PADDING_IDX,\n",
        "                        unk_idx=UNKNOWN_IDX,\n",
        "                        tokenizer=tokenizer,\n",
        "                        vocabulary=vocabulary\n",
        "                       )\n",
        "\n",
        "history = sp.training(model=model,\n",
        "            optimizer=optimizer,\n",
        "            loss_func=loss_func,\n",
        "            earlystopping=earlystopping,\n",
        "            df_train=df_train,\n",
        "            df_valid=df_valid,\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            accumulation_steps=5,\n",
        "            custom_test=\"i like you\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T09:38:24.022615Z",
          "iopub.execute_input": "2024-06-16T09:38:24.023045Z",
          "iopub.status.idle": "2024-06-16T10:43:26.536749Z",
          "shell.execute_reply.started": "2024-06-16T09:38:24.023020Z",
          "shell.execute_reply": "2024-06-16T10:43:26.535832Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSJjFgwEKi4H",
        "outputId": "2a59ed50-990c-44f5-be9d-0096a7be9ff3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: --------------------------------------------------------------------------------\n",
            "- Train loss: 1.231 - Valid loss: 1.018 - Time training: 1147.947\n",
            "Input 'en': i like you\n",
            "Output 'vi' generate: tôi như anh\n",
            "\n",
            "Epoch 2: --------------------------------------------------------------------------------\n",
            "- Train loss: 0.963 - Valid loss: 0.855 - Time training: 1146.813\n",
            "Input 'en': i like you\n",
            "Output 'vi' generate: tôi thích anh\n",
            "\n",
            "Epoch 3: --------------------------------------------------------------------------------\n",
            "- Train loss: 0.836 - Valid loss: 0.763 - Time training: 1148.343\n",
            "Input 'en': i like you\n",
            "Output 'vi' generate: tôi thích anh\n",
            "\n",
            "Epoch 4: --------------------------------------------------------------------------------\n",
            "- Train loss: 0.751 - Valid loss: 0.710 - Time training: 1145.543\n",
            "Input 'en': i like you\n",
            "Output 'vi' generate: tôi thích anh\n",
            "\n",
            "Epoch 5: --------------------------------------------------------------------------------\n",
            "- Train loss: 0.691 - Valid loss: 0.678 - Time training: 1145.465\n",
            "Input 'en': i like you\n",
            "Output 'vi' generate: tôi thích anh\n",
            "\n"
          ]
        }
      ],
      "id": "PSJjFgwEKi4H"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history['train_loss'], label = \"train loss\")\n",
        "plt.plot(history['valid_loss'], label = \"valid loss\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Loss');"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T10:43:26.542357Z",
          "iopub.execute_input": "2024-06-16T10:43:26.542628Z",
          "iopub.status.idle": "2024-06-16T10:43:26.877693Z",
          "shell.execute_reply.started": "2024-06-16T10:43:26.542605Z",
          "shell.execute_reply": "2024-06-16T10:43:26.876757Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "SlUKhGZ7Ki4H",
        "outputId": "3105b447-e5c1-4b36-876c-9a16eaedf29e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "id": "SlUKhGZ7Ki4H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "tti49i7KKi4H"
      },
      "id": "tti49i7KKi4H"
    },
    {
      "cell_type": "code",
      "source": [
        "def testing_generate(df, model, support:SupportTransformer, number=20,shuffle=False):\n",
        "    indexes = random.sample(range(len(df) + 1), number)\n",
        "    for index in indexes:\n",
        "        print('-' * 80,end='\\n\\n')\n",
        "        print(f\"Input '{support.src_language}': {df.iloc[index][support.src_language]}\")\n",
        "        print(f\"True Output '{support.tgt_language}': {df.iloc[index][support.tgt_language]}\")\n",
        "        print(f\"Generate Output '{support.tgt_language}': {support.generate(model,df.iloc[index][support.src_language])}\",end=\"\\n\\n\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T10:43:26.878839Z",
          "iopub.execute_input": "2024-06-16T10:43:26.879124Z",
          "iopub.status.idle": "2024-06-16T10:43:26.885452Z",
          "shell.execute_reply.started": "2024-06-16T10:43:26.879099Z",
          "shell.execute_reply": "2024-06-16T10:43:26.884538Z"
        },
        "trusted": true,
        "id": "Yx0U3bQJKi4H"
      },
      "execution_count": 31,
      "outputs": [],
      "id": "Yx0U3bQJKi4H"
    },
    {
      "cell_type": "code",
      "source": [
        "testing_generate(df_test, model, sp, number=20, shuffle=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T10:43:26.886417Z",
          "iopub.execute_input": "2024-06-16T10:43:26.886703Z",
          "iopub.status.idle": "2024-06-16T10:43:27.740927Z",
          "shell.execute_reply.started": "2024-06-16T10:43:26.886679Z",
          "shell.execute_reply": "2024-06-16T10:43:27.739975Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t17SXWalKi4H",
        "outputId": "36e25d8e-9aab-4ef1-cf4b-668effa4293d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': youre already in the public eye\n",
            "True Output 'vi': em đang trong tầm ngắm của công chúng\n",
            "Generate Output 'vi': anh đã nói với nhau về mắt\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': i expected people to be wondering why did i draw a sheep\n",
            "True Output 'vi': tôi tưởng mọi người đều sẽ thắc mắc tại sao tôi vẽ một con cừu\n",
            "Generate Output 'vi': tôi nghĩ người đang tự hỏi tại sao tôi lại vẽ một con cừu\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': pc world ↑ aul gabe may 20 2015\n",
            "True Output 'vi': pc world ↑ aul gabe 20 tháng 5 năm 2015\n",
            "Generate Output 'vi': máy tính thế giới ↑ “ tanner ” ↑ “ ”\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': bring water and a towel for the general\n",
            "True Output 'vi': mang nước và khăn đến cho đại nhân\n",
            "Generate Output 'vi': mang nước và một <unk> cho tướng\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': in the second step the sodium sulfate is crushed mixed with charcoal and limestone and again heated in a furnace\n",
            "True Output 'vi': trong bước thứ hai natri sulphat được nghiền nát trộn với than và đá vôi và nung nóng trong lò\n",
            "Generate Output 'vi': trong bước thứ hai <unk> <unk> bị <unk> <unk> với than và <unk> và một lần nữa làm <unk> trong một\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': the performers were chosen from among 12000 candidates and the castle in koszecin became their home base\n",
            "True Output 'vi': những người biểu diễn đã được chọn trong số 12000 ứng cử viên và lâu đài ở koszecin trở thành căn cứ của họ\n",
            "Generate Output 'vi': người biểu diễn đã được chọn từ giữa năm 5000 ứng cử viên và lâu đài ở <unk> trở thành căn cứ của họ\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': its a trip\n",
            "True Output 'vi': holly là một cuộc du ngoạn\n",
            "Generate Output 'vi': đó là chuyến đi\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': the puzzle will save the plane\n",
            "True Output 'vi': câu đố này sẽ cứu cái máy bay\n",
            "Generate Output 'vi': câu trả lời sẽ cứu máy bay\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': ouyahia obtained his diploma of baccalauréat èslettres in 1972\n",
            "True Output 'vi': ouyahia đã nhận được bằng tốt nghiệp baccalauréat èslettres năm 1972\n",
            "Generate Output 'vi': <unk> thu được bằng bằng cử nhân của ông bằng cử nhân\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': yes she is but shes doing a picture with rko\n",
            "True Output 'vi': ừ nhưng cô ta đang đóng phim với rko\n",
            "Generate Output 'vi': phải cô ấy nhưng cô ấy đang làm một bức ảnh\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': hope the ride helped you out\n",
            "True Output 'vi': hy vọng tôi đã giúp được anh\n",
            "Generate Output 'vi': hy vọng chuyến đi giúp anh ra ngoài\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': so you can put a scar like that on my cheek\n",
            "True Output 'vi': cho ông để sẹo lên má tôi sao\n",
            "Generate Output 'vi': vậy nên anh có thể đặt một cái mặt nạ như trên <unk> của\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': what you are doing is exactly what youve done your entire life\n",
            "True Output 'vi': việc con đang làm chính là điều con đã và đang làm suốt cuộc đời mình\n",
            "Generate Output 'vi': những gì anh đang làm chính xác là những gì anh làm cho toàn bộ\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': since most command signals were made with flags or signal lamps between ships the flagship was usually placed at the head of the centre column so that its signals might be more easily seen by the many ships of the formation\n",
            "True Output 'vi': do phần lớn mệnh lệnh được truyền đi bằng cờ và tín hiệu đèn kỳ hạm thường dẫn đầu hàng dọc ở trung tâm để các tàu trong đội hình có thể dễ dàng nhìn thấy tín hiệu phát ra\n",
            "Generate Output 'vi': từ khi các tín hiệu được đưa ra với các lá cờ hoặc tín hiệu đèn giữa tàu khu trục thường được đặt tại đầu của trung tâm trung tâm của trung tâm và tín hiệu đó có thể dễ dàng thấy được nhiều con tàu sân bay\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': and challenging valina is the lovely and sweet\n",
            "True Output 'vi': đối thủ của valina là một người đáng yêu và ngọt ngào\n",
            "Generate Output 'vi': và thách thức <unk> là một món quà dễ thương và\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': why didnt you tell me that youre pregnant\n",
            "True Output 'vi': sao không cho anh biết em đã có thai\n",
            "Generate Output 'vi': sao anh không nói với tôi rằng cô đang\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': the child traveled on the same vietnam airlines flight vn0062 as the 314th patient whom he was in close contact with in russia the national steering committee for covid19 infection prevention and control announced in a statement this morning may 30\n",
            "True Output 'vi': em bé đi cùng chuyến bay của vietnam airlines vn0062 với tư cách là bệnh nhân thứ 314 người mà em tiếp xúc gần gũi ở nga theo ban chỉ đạo quốc gia về phòng chống và kiểm soát nhiễm trùng covid19 đã công bố trong một bài phát biểu vào sáng nay 305\n",
            "Generate Output 'vi': đứa trẻ đi du lịch cùng với các hãng hàng không việt nam đã bay <unk> như bệnh nhân của bệnh nhân người mà ông đang tiếp xúc với nga trong ban quản lý quốc gia này cho các cơ quan nhiễm covid19 và kiểm soát covid19 vào ngày 30 tháng 5\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': it is a doublestranded dna virus and is a member of the nucleocytoplasmic large dna viruses clade\n",
            "True Output 'vi': đây là một loại virus adn xoắn kép và là thành viên của nhánh các virus adn lớn nhân tế bào chất\n",
            "Generate Output 'vi': nó là một virus dna và là một thành viên của virus <unk> dna lớn\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': for instance the mid vowels are written é è ô o in french are written e ɛ o ɔ in beninese languages whereas the consonants are written ng and sh or ch in english are written ŋ and c\n",
            "True Output 'vi': ví dụ các ngữ âm giữa viết é è ô o trong tiếng pháp được viết e ɛ o ɔ trong các ngôn ngữ tại bénin trong khi các phụ âm được viết ng và sh hay ch trong tiếng anh được viết ŋ và c\n",
            "Generate Output 'vi': ví dụ giữa các sợi sợi giữa các sợi chứa <unk> bao gồm <unk> <unk> <unk> trong tiếng pháp tiếng <unk> trong tiếng <unk> trong tiếng ả rập được viết lại và tiếng anh\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Input 'en': so you could change it like paul wilkerman wanted and his heirs get nothing\n",
            "True Output 'vi': vậy là ông có thể thay đổi nó như paul wilkerman muốn và con ông ta chả có gì hết\n",
            "Generate Output 'vi': vậy nên bạn có thể thay đổi nó như paul <unk> muốn và người thừa kế của ông\n",
            "\n"
          ]
        }
      ],
      "id": "t17SXWalKi4H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model & support"
      ],
      "metadata": {
        "id": "q6Gt4d1LKi4H"
      },
      "id": "q6Gt4d1LKi4H"
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = './model/translator_EnVi.pth'\n",
        "OPTIMIZER_PATH = './model/optimizer.pth'\n",
        "SUPPORT_PATH = './model/support_transformer.pkl'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T10:43:27.742114Z",
          "iopub.execute_input": "2024-06-16T10:43:27.742960Z",
          "iopub.status.idle": "2024-06-16T10:43:27.746498Z",
          "shell.execute_reply.started": "2024-06-16T10:43:27.742930Z",
          "shell.execute_reply": "2024-06-16T10:43:27.745534Z"
        },
        "trusted": true,
        "id": "rJhOWx64Ki4H"
      },
      "execution_count": 33,
      "outputs": [],
      "id": "rJhOWx64Ki4H"
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./model/', exist_ok=True)\n",
        "\n",
        "# Save model state_dict\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "\n",
        "# Save optimizer state_dict\n",
        "torch.save(optimizer.state_dict(), OPTIMIZER_PATH)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T10:43:27.747488Z",
          "iopub.execute_input": "2024-06-16T10:43:27.747778Z",
          "iopub.status.idle": "2024-06-16T10:43:30.534460Z",
          "shell.execute_reply.started": "2024-06-16T10:43:27.747751Z",
          "shell.execute_reply": "2024-06-16T10:43:30.533661Z"
        },
        "trusted": true,
        "id": "8JP0RiugKi4I"
      },
      "execution_count": 34,
      "outputs": [],
      "id": "8JP0RiugKi4I"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save helper\n",
        "with open(SUPPORT_PATH, 'wb') as f:\n",
        "    pickle.dump(sp, f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T10:59:51.044916Z",
          "iopub.execute_input": "2024-06-16T10:59:51.045568Z",
          "iopub.status.idle": "2024-06-16T10:59:51.096550Z",
          "shell.execute_reply.started": "2024-06-16T10:59:51.045534Z",
          "shell.execute_reply": "2024-06-16T10:59:51.095583Z"
        },
        "trusted": true,
        "id": "HFWze9rPKi4I"
      },
      "execution_count": 35,
      "outputs": [],
      "id": "HFWze9rPKi4I"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete Generative Translator"
      ],
      "metadata": {
        "id": "Zhgwarc0Ki4I"
      },
      "id": "Zhgwarc0Ki4I"
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Here\n",
        "sentence = \"who i am?\"\n",
        "sp.completely_generate(model, sentence)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T10:59:52.347193Z",
          "iopub.execute_input": "2024-06-16T10:59:52.347858Z",
          "iopub.status.idle": "2024-06-16T10:59:52.379062Z",
          "shell.execute_reply.started": "2024-06-16T10:59:52.347826Z",
          "shell.execute_reply": "2024-06-16T10:59:52.378236Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7NeSqoV2Ki4I",
        "outputId": "83b481c6-4729-4e39-b88b-ca4d300bae96"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ai tôi là ai'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "id": "7NeSqoV2Ki4I"
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I don't know\"\n",
        "sp.completely_generate(model, sentence)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-16T10:59:53.275138Z",
          "iopub.execute_input": "2024-06-16T10:59:53.275521Z",
          "iopub.status.idle": "2024-06-16T10:59:53.312431Z",
          "shell.execute_reply.started": "2024-06-16T10:59:53.275492Z",
          "shell.execute_reply": "2024-06-16T10:59:53.311617Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IVy9O6vWKi4I",
        "outputId": "70d6da6e-1186-45f3-abfa-88f0cac586f5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tôi không biết'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "id": "IVy9O6vWKi4I"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BLEU"
      ],
      "metadata": {
        "id": "kto4_K5dHtiC"
      },
      "id": "kto4_K5dHtiC"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAaMgUwpHxmZ",
        "outputId": "9bd65f9b-bf9b-4515-96f1-c29e886b0bf8"
      },
      "id": "LAaMgUwpHxmZ",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# Load model, optimizer, and support transformer if needed\n",
        "MODEL_PATH = './model/translator_EnVi.pth'\n",
        "OPTIMIZER_PATH = './model/optimizer.pth'\n",
        "SUPPORT_PATH = './model/support_transformer.pkl'\n",
        "\n",
        "# Load the saved model\n",
        "model = TransformerModel(src_vocab_size=src_vocab_size,\n",
        "                         tgt_vocab_size=tgt_vocab_size,\n",
        "                         d_model=d_model,\n",
        "                         nhead=nhead,\n",
        "                         num_encoder_layers=num_encoder_layers,\n",
        "                         num_decoder_layers=num_decoder_layers,\n",
        "                         dim_feedforward=dim_feedforward,\n",
        "                         dropout=dropout)\n",
        "model.load_state_dict(torch.load(MODEL_PATH))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Load the support transformer\n",
        "with open(SUPPORT_PATH, 'rb') as f:\n",
        "    support_transformer = pickle.load(f)\n",
        "\n",
        "def calculate_bleu(model, support_transformer, df_test, device):\n",
        "    bleu_scores = []\n",
        "    chencherry = SmoothingFunction()\n",
        "\n",
        "    for idx, row in df_test.iterrows():\n",
        "        src_sentence = row[support_transformer.src_language]\n",
        "        reference_sentence = row[support_transformer.tgt_language]\n",
        "\n",
        "        generated_sentence = support_transformer.generate(model, src_sentence)\n",
        "\n",
        "        reference_tokens = support_transformer.tokenizer[support_transformer.tgt_language](reference_sentence)\n",
        "        generated_tokens = support_transformer.tokenizer[support_transformer.tgt_language](generated_sentence)\n",
        "\n",
        "        bleu_score = sentence_bleu([reference_tokens], generated_tokens, smoothing_function=chencherry.method1)\n",
        "        bleu_scores.append(bleu_score)\n",
        "\n",
        "    return sum(bleu_scores) / len(bleu_scores)\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu_score = calculate_bleu(model, support_transformer, df_test, device)\n",
        "print(f\"BLEU score: {bleu_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxw_rYSiH0al",
        "outputId": "5cc3bea6-1625-487b-dc9a-fc24450f758f"
      },
      "id": "Wxw_rYSiH0al",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score: 0.1349\n"
          ]
        }
      ]
    }
  ]
}